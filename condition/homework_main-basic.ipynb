{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQEE_HYiSJq_"
   },
   "source": [
    "# Homework: Basic Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sM8buXbJSJrB"
   },
   "source": [
    "The goal of this homework is simple, yet an actual implementation may take some time :). We are going to write an Artificial Neural Network (almost) from scratch. The software design was heavily inspired by [PyTorch](http://pytorch.org) which is the main framework in ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VtPNGefu24Z"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from time import time, sleep\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kRAnv3TShQm"
   },
   "outputs": [],
   "source": [
    "# Import your google drive with notebooks\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJk0j_h6S1ns"
   },
   "outputs": [],
   "source": [
    "# move to folder with homework (all files need to be in one folder)\n",
    "%cd '/content/drive/MyDrive/smthg/path_to_folder/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hf78U3G3TPcn"
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "%run homework_modules.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh4TGfLOSJrD"
   },
   "source": [
    "# Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7cTVGh0SJrD"
   },
   "source": [
    "Implement everything in `Modules.ipynb`. Read all the comments thoughtfully to ease the pain. Please try not to change the prototypes.\n",
    "\n",
    "Do not forget, that each module should return **AND** store `output` and `gradInput`.\n",
    "\n",
    "The typical assumption is that `module.backward` is always executed after `module.forward`,\n",
    "so `output` is stored, this would be useful for `SoftMax`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJeCVdsKSJrE"
   },
   "source": [
    "### Tech note\n",
    "Prefer using `np.multiply`, `np.add`, `np.divide`, `np.subtract` instead of `*`,`+`,`/`,`-` for better memory handling.\n",
    "\n",
    "Example: suppose you allocated a variable\n",
    "\n",
    "```\n",
    "a = np.zeros(...)\n",
    "```\n",
    "So, instead of\n",
    "```\n",
    "a = b + c  # will be reallocated, GC needed to free\n",
    "```\n",
    "You can use:\n",
    "```\n",
    "np.add(b,c,out = a) # puts result in `a`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFMv_N0uSJrE"
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cNuDlsFSJrE"
   },
   "source": [
    "This task is aimed at testing the skill of a data analyst.\n",
    "\n",
    "Remember, you don't always need to use a large neural network to solve a problem, sometimes it's enough just to look carefully at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMlZAjsKdCQD"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/table_data_train.csv')\n",
    "test_df = pd.read_csv('data/table_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hxqt336dZp1"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7h6gnVyfKl_"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPbqkNVaf7h0"
   },
   "source": [
    "First of all, look at the data, guess where this data comes from, what it is about, what is the most important variable that can be predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DAqrUtzsf8UT"
   },
   "source": [
    "***Your opinion here:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHbi2nCVgwD6"
   },
   "source": [
    "#### 1. Check data types and missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eH3kU4NLgAbv"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swrl8ZFlg8xW"
   },
   "source": [
    "#### 2. Numerical Features Analysis\n",
    "\n",
    "Calculate the mean values of Total day minutes, Total intl charge, Customer service calls for churned (Churn=1) and retained (Churn=0) customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PR7_06ghaVz"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJrtwCW4hevi"
   },
   "source": [
    "#### 3. Distribution Visualization\n",
    "\n",
    "- Create a histogram of `Customer service calls` for `Churn=0` and `Churn=1` on the same plot.\n",
    "\n",
    "- Create a boxplot for `Total day minutes` segmented by Churn.\n",
    "\n",
    "- Create a bar chart showing the churn rate for `International plan` (Yes/No)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rc_ynOKChc2S"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dhb3Exjthtjc"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cL1CnhEbh1PE"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgIb_M1giJSr"
   },
   "source": [
    "####4. Correlation Analysis\n",
    "\n",
    "Find the top 3 features with the highest Pearson correlation to `Churn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSLEd5zWiFaO"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3FCu19hiQMY"
   },
   "source": [
    "####5. Decision Rule Without ML\n",
    "\n",
    "Create a rule to predict Churn using no more than 3 conditions. You can perform any additional analysis that you deem necessary.\n",
    "\n",
    "Achieve accuracy ≥ 0.75 on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUX6I_RijjSF"
   },
   "outputs": [],
   "source": [
    "# Your analysis below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYQ2WRG8jtWw"
   },
   "outputs": [],
   "source": [
    "def custom_rule(df):\n",
    "    # Your code goes here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjLMX88GiXqu"
   },
   "outputs": [],
   "source": [
    "test_df['Predicted'] = custom_rule(test_df)\n",
    "accuracy = (test_df['Predicted'] == test_df['Churn']).mean()\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "\n",
    "assert accuracy >= 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJLrW3ChSJrH"
   },
   "source": [
    "# Digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkMrYO4jL5W4"
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaqP8RFZSJrH"
   },
   "source": [
    "We are using old good [MNIST](http://yann.lecun.com/exdb/mnist/) as our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmyVodkfSJrH"
   },
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    # Read the inputs in Yann LeCun's binary format.\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    # The inputs are vectors now, we reshape them to monochrome 2D images\n",
    "    data = data.reshape(-1, 28, 28)\n",
    "    # The inputs come as bytes, we convert them to float32 in range [0,1].\n",
    "    return (data / np.float32(256)).squeeze()\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    # Read the labels in Yann LeCun's binary format.\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    # The labels are vectors of integers now, that's exactly what we want.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1o7aAXiIES-m"
   },
   "outputs": [],
   "source": [
    "X_train = load_image('data/train-images-idx3-ubyte.gz')\n",
    "X_test = load_image('data/t10k-images-idx3-ubyte.gz')\n",
    "Y_train = load_mnist_labels('data/train-labels-idx1-ubyte.gz')\n",
    "Y_test = load_mnist_labels('data/t10k-labels-idx1-ubyte.gz')\n",
    "# We reserve the last 10000 training examples for validation.\n",
    "X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "Y_train, Y_val = Y_train[:-10000], Y_train[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAhzIGXHvEZz"
   },
   "outputs": [],
   "source": [
    "print('X_train: ' + str(X_train.shape))\n",
    "print('Y_train: ' + str(Y_train.shape))\n",
    "print('X_val: ' + str(X_val.shape))\n",
    "print('Y_val: ' + str(Y_val.shape))\n",
    "print('X_test:  '  + str(X_test.shape))\n",
    "print('Y_test:  '  + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEfzATX8vFZK"
   },
   "outputs": [],
   "source": [
    "plt.subplot(331)\n",
    "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
    "plt.show()\n",
    "print()\n",
    "print('Y_train[0]: ' + str(Y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1qI1FscvHm0"
   },
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gR908vNhSJrH"
   },
   "source": [
    "### Task 1:\n",
    "\n",
    "make one-hot encoding for labels. Clue: use [np.eye](https://numpy.org/doc/stable/reference/generated/numpy.eye.html) for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1YkKkzcSJrH"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(y):\n",
    "    # YOUR CODE HERE:\n",
    "    ###########################\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    ###########################\n",
    "    one_hot_y = None\n",
    "    return one_hot_y\n",
    "\n",
    "hot_y_train = one_hot_encode(Y_train)\n",
    "hot_y_val = one_hot_encode(Y_val)\n",
    "hot_y_test = one_hot_encode(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JixbGbGxErr-"
   },
   "source": [
    "#### Test task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1neA_xfEkM6"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode_test(hot_y_train):\n",
    "    first_ten_answers = np.array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
    "                        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
    "                        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
    "                        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "                        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])\n",
    "    np.testing.assert_equal(hot_y_train[:10], first_ten_answers, err_msg=\"First ten samples are not equal\")\n",
    "    print(\"The test pass successfully !!!\")\n",
    "\n",
    "one_hot_encode_test(hot_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnAJSxwMEgMV"
   },
   "source": [
    "### Task 2:  \n",
    "\n",
    "In `homework_main-basic.ipynb` we treated mnist images as vectors, so we flattened it. For CNN, we assume that images have size `(bs, num_channels, w, h)`. Our mnist image is grayscale, so, it don't have a `num_channels` dimension. You need to reshape `X_train`, `X_val` and `X_test` to appropriate size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLEMy1YQEe0f"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE:\n",
    "###########################\n",
    "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "###########################\n",
    "X_train, X_val, X_test = None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1jGjw3NFRaN"
   },
   "source": [
    "#### Test Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9O34it-jEfCS"
   },
   "outputs": [],
   "source": [
    "def dimension_test(X_train, X_val, X_test):\n",
    "    true_train_shape = (50000, 784)\n",
    "    true_test_shape = (10000, 784)\n",
    "    np.testing.assert_equal(X_train.shape, true_train_shape, err_msg=\"Train shape doesn't the same\")\n",
    "    np.testing.assert_equal(X_val.shape, true_test_shape, err_msg=\"Train shape doesn't the same\")\n",
    "    np.testing.assert_equal(X_test.shape, true_test_shape, err_msg=\"Train shape doesn't the same\")\n",
    "    print(\"The test pass successfully !!!\")\n",
    "\n",
    "dimension_test(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvqVc0lLLxJy"
   },
   "source": [
    "### Compare activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2U3QH5GMBW_"
   },
   "source": [
    "- **Compare** `ReLU`, `ELU`, `LeakyReLU`, `SoftPlus` activation functions.\n",
    "You would better pick the best optimizer params for each of them, but it is overkill for now.\n",
    "\n",
    "- **Try** inserting `BatchNormalization` (folowed by `ChannelwiseScaling`) between `Linear` module and activation functions.\n",
    "\n",
    "- Fill blanks in the code below\n",
    "\n",
    "- Plot the losses both from activation functions comparison and `BatchNormalization` comparison on one plot. Please find a scale (log?) when the lines are distinguishable, do not forget about naming the axes, the plot should be goodlooking.\n",
    "\n",
    "- Hint: good logloss for MNIST should be around 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCUatzxJlPto"
   },
   "outputs": [],
   "source": [
    "# batch generator\n",
    "def get_batches(dataset, batch_size):\n",
    "    X, Y = dataset\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    # Shuffle at the start of epoch\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        batch_idx = indices[start:end]\n",
    "        yield X[batch_idx], Y[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJtrgXMNSJrI"
   },
   "outputs": [],
   "source": [
    "# Your code goes here.\n",
    "def get_optimizer(optimizer_name):\n",
    "    if optimizer_name == 'sgd_momentum':\n",
    "        optimizer_config = # Your code goes here\n",
    "        optimizer_state = {}\n",
    "\n",
    "    elif optimizer_name == 'adam_optimizer':\n",
    "        optimizer_config = # Your code goes here\n",
    "        optimizer_state = {}\n",
    "\n",
    "    else:\n",
    "        raise NameError('Optimizer name have to one of {\\'sgd_momentum\\', \\'adam_optimizer\\'}')\n",
    "\n",
    "    return optimizer_config, optimizer_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zUphy2LJ4cH"
   },
   "outputs": [],
   "source": [
    "def train(net, criterion, optimizer_name, n_epoch,\n",
    "          X_train, y_train, X_val, y_val, batch_size):\n",
    "\n",
    "    loss_train_history = []\n",
    "    loss_val_history = []\n",
    "    optimizer_config, optimizer_state = get_optimizer(optimizer_name)\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        print('Epoch {}/{}:'.format(i, n_epoch - 1), flush=True)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                X = X_train\n",
    "                y = y_train\n",
    "                net.train()\n",
    "            else:\n",
    "                X = X_val\n",
    "                y = y_val\n",
    "                net.evaluate()\n",
    "\n",
    "            num_batches = X.shape[0] / batch_size\n",
    "            running_loss = 0.\n",
    "            running_acc = 0.\n",
    "\n",
    "            for x_batch, y_batch in get_batches((X, y), batch_size):\n",
    "\n",
    "                net.zeroGradParameters()\n",
    "\n",
    "                # Forward\n",
    "                predictions = # Your code goes here\n",
    "                loss = # Your code goes here\n",
    "\n",
    "                # Backward\n",
    "                if phase == 'train':\n",
    "                    # Your code goes here\n",
    "\n",
    "                    # Update weights\n",
    "                    if optimizer_name == 'sgd_momentum':\n",
    "                        # Your code goes here\n",
    "                    else:\n",
    "                        # Your code goes here\n",
    "\n",
    "                running_loss += loss\n",
    "                running_acc += np.sum(predictions.argmax(axis=1) == y_batch.argmax(axis=1))\n",
    "\n",
    "            epoch_loss = running_loss / num_batches\n",
    "            epoch_acc = running_acc / y.shape[0]\n",
    "            if phase == 'train':\n",
    "                loss_train_history.append(epoch_loss)\n",
    "            else:\n",
    "                loss_val_history.append(epoch_loss)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n",
    "\n",
    "    return net, loss_train_history, loss_val_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPiyn8CqJ27_"
   },
   "outputs": [],
   "source": [
    "def test(net, criterion, X_test, y_test, batch_size):\n",
    "    net.evaluate()\n",
    "    num_batches = X_test.shape[0] / batch_size\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    for x_batch, y_batch in get_batches((X_test, y_test), batch_size):\n",
    "        net.zeroGradParaameters()\n",
    "\n",
    "        # Forward\n",
    "        predictions = # Your code goes here\n",
    "        loss = # Your code goes here\n",
    "        running_loss += loss\n",
    "        running_acc += (predictions.argmax(axis=1) == y_batch.argmax(axis=1)).astype(float).mean()\n",
    "\n",
    "    epoch_loss = running_loss / num_batches\n",
    "    epoch_acc = running_acc / num_batches\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksbNpXpaJ2Gf"
   },
   "outputs": [],
   "source": [
    "def get_net(activation=ReLU, norm=False):\n",
    "    net = Sequential()\n",
    "    net.add(Linear(28*28, 100))\n",
    "    if norm:\n",
    "        net.add(BatchNormalization(alpha=0.0001))\n",
    "        net.add(ChannelwiseScaling(100))\n",
    "    net.add(activation())\n",
    "    net.add(Linear(100, 10))\n",
    "    if norm:\n",
    "        net.add(BatchNormalization(alpha=0.0001))\n",
    "        net.add(ChannelwiseScaling(10))\n",
    "    net.add(LogSoftMax())\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtYTXHWLRW4E"
   },
   "outputs": [],
   "source": [
    "# Fix parametrs (you can change it if you want)\n",
    "batch_size = 64\n",
    "n_epoch = 15\n",
    "criterion = ClassNLLCriterion()\n",
    "optimizer_name = 'sgd_momentum'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbQSyQNTUR5y"
   },
   "outputs": [],
   "source": [
    "nets = []\n",
    "activations = # Your code goes here\n",
    "\n",
    "for activ in activations:\n",
    "    # Your code goes here\n",
    "    # Add nets for all activation with or without Batch Normalization\n",
    "    # Use `get_net` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "kRPhPn6iUVH7"
   },
   "outputs": [],
   "source": [
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for i, net in enumerate(nets):\n",
    "    print(f'\\n\\nTrain net {i}/{len(nets)}')\n",
    "    # Your code goes here\n",
    "    # Train net and save net, losses on train and validation\n",
    "    # Use `train` function\n",
    "    # This may take up to 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "JxWwJdiFUYE6"
   },
   "outputs": [],
   "source": [
    "for net in nets:\n",
    "    # Your code goes here\n",
    "    # Test net and print loss and accuracy\n",
    "    # Use `test` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHDGKELeUikA"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your code goes here\n",
    "# Plot train and validation loss for all nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bT7h8lNAMdFu"
   },
   "source": [
    "### Compare optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XE6jCUcMgZa"
   },
   "source": [
    "- Plot the losses for two networks: one trained by momentum_sgd, another one trained by Adam. Which one performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "429oLbAkLSyJ"
   },
   "outputs": [],
   "source": [
    "nets = []\n",
    "optimizer_names = ['sgd_momentum', 'adam_optimizer']\n",
    "\n",
    "for optim_name in optimizer_names:\n",
    "    nets.append(get_net(activation=ReLU, norm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoiTRgQJNKDm"
   },
   "outputs": [],
   "source": [
    "criterion = ClassNLLCriterion()\n",
    "batch_size = 64\n",
    "n_epoch = 15\n",
    "\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "for i, net in enumerate(nets):\n",
    "    # Your code goes here\n",
    "    # Train net and save net, losses on train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvczXYI8NS2I"
   },
   "outputs": [],
   "source": [
    "for net in nets:\n",
    "    # Your code goes here\n",
    "    # Test net and print loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHrebdQjNXIM"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your code goes here\n",
    "# Plot train and validation loss for nets trained by sgd momentum and adam optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMaF063_Ns18"
   },
   "source": [
    "### Your conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIAAwTrAUt4z"
   },
   "source": [
    "What conclusions did you draw for yourself? Write your conclusion on the work done.\n",
    "\n",
    "You can rely on the questions below:\n",
    "\n",
    "- Which activation functions provide the best accuracy?\n",
    "\n",
    "- Are there differences in training stability when using different activation functions?\n",
    "\n",
    "- How does batch normalization affect the model's training speed?\n",
    "\n",
    "- Does batch normalization improve the model's accuracy on the test dataset?\n",
    "\n",
    "- How does batch normalization affect training stability?\n",
    "\n",
    "- Which activation function provided the greatest improvement in performance when combined with batch normalization?\n",
    "\n",
    "- How does the convergence speed of SGD with momentum compare to that of Adam?\n",
    "\n",
    "- Are there differences in training stability when using SGD with momentum versus Adam?\n",
    "\n",
    "- How does the loss function behave over epochs for each optimizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwfKCIHfXimo"
   },
   "source": [
    "***Your answer here***:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKuwbDyQN05H"
   },
   "source": [
    "### Custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCIPqaj8SJrI"
   },
   "source": [
    "**Finally**, use all your knowledge to build a super cool model on this dataset. Use **dropout** to prevent overfitting, play with **learning rate decay**. You can use **data augmentation** such as rotations, translations to boost your score. Use your knowledge and imagination to train a model. Don't forget to call `training()` and `evaluate()` methods to set desired behaviour of `BatchNormalization` and `Dropout` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kuiraFvSJrI"
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "# Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGAj-MSuvoSy"
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "# Train your custom architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVTuZeTcOhSJ"
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "# Plot validation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XgTc3_2SJrJ"
   },
   "source": [
    "Print here your accuracy on test set. It should be around 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ze452APWOvw5"
   },
   "outputs": [],
   "source": [
    "# Your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89GSHfEyU4mv"
   },
   "source": [
    "### Comparing with PyTorch implementation\n",
    "The last (and maybe the easiest step after compared to the previous tasks: build a network with the same architecture as above now with PyTorch.\n",
    "__Good Luck!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-BgOEEoUU5RE"
   },
   "outputs": [],
   "source": [
    "# Your beautiful code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
